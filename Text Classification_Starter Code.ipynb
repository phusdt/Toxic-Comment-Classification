{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text Classification_Starter Code.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3AkEoCKaHdpj"},"source":["\n","In this notebook, we will try the process of implementing RNN with Keras in order to classify text sentences.\n","\n","I.   **Firstly**, we'll import useful packages.\n","\n","II.   **Then**, we'll load the data and create a word embedding matrix using Glove.\n","\n","III.  **We'll try a simple RNN model** and then we will evaluate its performances.\n","\n","IV. Finally, we'll use techniques to increase our model's accuracy."]},{"cell_type":"markdown","metadata":{"id":"_xY_w9I1cZni"},"source":["**Task 1:** Setting Fre GPU in this Google Colab notebook."]},{"cell_type":"markdown","metadata":{"id":"H4iAL0E0ciDS"},"source":["## Mounting Google Drive locally\n","**Task 2:** Mount the Google Driver into the Google Colab Driver.\n"]},{"cell_type":"code","metadata":{"id":"I8iz8Rp8H5pG"},"source":["## TYPE YOUR CODE for task 2 here:"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LeAakuO9cD5s"},"source":["# I. Let import all useful packages."]},{"cell_type":"code","metadata":{"id":"TWgEP6KSHmV_"},"source":["import sys, os, re, csv, codecs, numpy as np, pandas as pd\n","import tensorflow.keras\n","import datetime\n","from tensorflow.keras import backend as K\n","import tensorflow.keras.optimizers as Optimizer\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n","from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n","from tensorflow.keras.models import Model, load_model\n","import tensorflow_addons as tfa\n","\n","from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n","from sklearn.metrics import confusion_matrix as CM\n","from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n","import matplotlib.pyplot as plot\n","import seaborn as sn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZvFTfBIscRwC"},"source":["**Task 3**: Copy the dataset from Google Drive into Colab"]},{"cell_type":"code","metadata":{"id":"MzzQsanZIZfg"},"source":["## TYPE YOUR CODE for task 3 here:"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D_GxFMl7dFJ-"},"source":["# II. Load the data.\n","\n","## About dataset.\n","An invalid question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is invalid:\n","\n","* Has a non-neutral tone.\n","* Is disparaging or inflammatory.\n","* Isn't grounded in reality.\n","* Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers\n","\n","The data includes the question that was asked, and whether it was identified as invalid (target = 1). "]},{"cell_type":"markdown","metadata":{"id":"A9HhWwT-gpuN"},"source":["**Task 4**: Load the dataset.\n","* Load the data from CSV file.\n","* Remove all the rows with NA values.\n","* Split the data into 3 set: Training set, validation set and test set (0.9/0.05/0.05, random_seed = 9) with a same ratio of data number beween each class.\n","* Print out these dataset's description.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"j9HMbZrqK1Rq"},"source":["def load_data(data_link):\n","    '''\n","    input: data link.\n","    output:\n","        train_set, validation_set and test_set(0.95/0.05/0.05) without NA values.\n","    '''\n","    ## TYPE YOUR CODE for task 4 here:\n","\n","\n","    return train, validation, test\n","\n","train_set, validation_set, test_set = load_data('train.csv')\n","print(train_set['label'].describe())\n","print(validation_set['label'].describe())\n","print(test_set['label'].describe())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sIcOnRkbqofC"},"source":["# Encoding text data.\n","Let declare some fundamental parameters first:"]},{"cell_type":"code","metadata":{"id":"0F3_zcCjHwzm"},"source":["embed_size = 50 # how big is each word vector\n","max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n","max_len = 50 # max number of words in a question to use\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vT8m71iixjxt"},"source":["**Task 5:** Encode the dataset using Tokenizer and one-hot encoding vector.\n","* Encode the text (question_text column) by turning each question text into a list of word indexes using [Tokenizer](https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do) with **max_features** and all the text sentences from the training and the validation set. \n","* Turn each list of word indexes into an equal length - **max_len** (with truncation or padding as needed) using [pad_sequences](https://keras.io/preprocessing/sequence/).\n","* Encode the label (label column) using [to_categorical](https://keras.io/utils/) function on Keras."]},{"cell_type":"code","metadata":{"id":"Q1MZKNs4xmfP"},"source":["def encoding_textdata(train_set, validation_set, test_set, max_features, max_len):\n","    '''\n","    Input:\n","    - Train/validation/test dataset.\n","    - max_features, max_len.\n","    Output:\n","    - X train/validation/test, y train/validation/test.\n","    - Tokenizer.\n","    '''\n","    ## TYPE YOUR CODE for task 5 here:\n","\n","    return (X_tr, y_tr), (X_va, y_va), (X_te, y_te), tokenizer\n","\n","(X_tr, y_tr), (X_va, y_va), (X_te, y_te), tokenizer = encoding_textdata(train_set, validation_set, test_set, max_features, max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9kpG-p30WUcc"},"source":["**Task 6**: Create word embedding matrix.\n","* Firstly, write a function to [load the GloVe dictionary.](https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db)\n","* Then, create a word embedding matrix using GloVe dictionary with these parameters:\n","    - Word embedding matrix shape: (Number of word, embed_size).\n","    - Embed size: 50.\n","    - Number of words: The minimum of (max_features, len(word_index)), while word_index is the dictionary of word which contains in tokenizer.\n","    - If a word occurs in GloVe dictionary, we should take its initialization value as in GloVe dictionary. Otherwise, take a normal random value with mean and std as mean and std of GloVe dictionary value.\n","    \n","\n"]},{"cell_type":"code","metadata":{"id":"47s8-SncWT3V"},"source":["\n","def get_coefs(word,*arr): \n","    return word, np.asarray(arr, dtype='float32')\n","def get_GloVe_dict(GloVe_link):\n","    '''\n","    input: GloVe link.\n","    output: GloVe dictionary.\n","    '''\n","    ## TYPE YOUR CODE for task 6 here:\n","    \n","GloVe_link = 'glove.6B.50d.txt'\n","GloVe_dict = get_GloVe_dict(GloVe_link)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXRyFSLtr4_k"},"source":["def create_embedding_matrix(GloVe_dict, tokenizer, max_features):\n","    '''\n","    input: GloVe dictionaray, tokenizer from training and validation dataset, number of max features.\n","    output: Word embedding matrix.\n","    '''\n","    \n","    ## TYPE YOUR CODE for task 6 here:\n","    \n","    \n","    return embedding_matrix\n","\n","embedding_matrix = create_embedding_matrix(GloVe_dict, tokenizer, max_features)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NWybjdQkqWrg"},"source":["III. Modelling\n","There are some steps we need to finish:\n","Build the model.\n","\n","Compile the model.\n","\n","Train / fit the data to the model.\n","\n","Evaluate the model on the testing set."]},{"cell_type":"markdown","metadata":{"id":"I6AMfqQkqcET"},"source":["## Build the model\n","**Task 7:** We can build an easy model composed of different layers such as:\n","* [Embedding](https://keras.io/layers/embeddings/) layer with max_features, embed_size and embedding_matrix.\n","* [Bidirectional LSTM layer](https://keras.io/examples/imdb_bidirectional_lstm/) with number of hidden state = 50, dropout_rate = 0.1 and recurrent_dropout_rate = 0.1.\n","* GlobalMaxPool1D.\n","* Dense with number of unit = 50, activation = 'relu'.\n","* Dropout with rate = 0.1.\n","* Final dense with number of unit = number of class, activation = 'sigmoid'."]},{"cell_type":"code","metadata":{"id":"J7_eizWaqi_7"},"source":["def create_model(max_len, max_features, embed_size):\n","    '''\n","    input: max_len, max_features, embed_size\n","    output: model.\n","    '''\n","    ## TYPE YOUR CODE for task 7 here:\n","    \n","    \n","    return model\n","\n","model = create_model(max_len, max_features, embed_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lWcBKhzMux9Z"},"source":["**Task 8:** Compile the model and setup the callback. Then print out the model summary.\n","* [Compile](https://keras.io/models/model/#compile) the model with Adam Optimizaer, lr = 1e-2, suitable loss for binary classification problem and [\"F1-score\"](https://github.com/tensorflow/addons/issues/825) as metric.\n","* Print out the model summary."]},{"cell_type":"code","metadata":{"id":"P9l8EbG0ur1F"},"source":["def optimize(model):\n","    '''\n","    Input: \n","        Model.\n","    Return: \n","        Complied model.\n","    '''\n","    ## TYPE YOUR CODE for task 8 here:\n","    \n","    return model\n","\n","model = optimize(model)\n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0BlenccGzLVr"},"source":["**Task 9**: Setup callback.\n","* Create the [tensorboard callback](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks) to save the logs.\n","* Create the [checkpoint callback](https://machinelearningmastery.com/check-point-deep-learning-models-keras/) to save the checkpoint with the best accuracy after each epoch.\n","* Create the [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau) callback with factor=0.3, patience=1 and \"Validation F1-score\" monitor.\n","* Create the [early stopping callback](https://keras.io/callbacks/#earlystopping) with patience=7, mode = 'max' and \"Validation F1-score\" monitor.\n","\n"]},{"cell_type":"code","metadata":{"id":"I6x6dteutin0"},"source":["def callback_model(checkpoint_name, logs_name):\n","    '''\n","    Input: \n","        Best checkpoint name, logs name.\n","    Return: \n","        Callback list, which contains tensorboard callback and checkpoint callback.\n","    '''\n","    ## TYPE YOUR CODE for task 9 here:\n","\n","    return callbacks_list\n","\n","checkpoint_name = 'weights.best.hdf5'\n","logs_name = 'training_logs'\n","callbacks_list = callback_model(checkpoint_name, logs_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHTwh8OyvGqa"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9nDCsHAC2HwW"},"source":["**Task 10:** Train the model.\n","\n","* Train the model with 20 epochs with batch_size = 4096.\n","* Return the model with best-checkpoint weights.\n","\n","*Hint*: Fit the model first, then reload the model (load_model function) with best-checkpoint weights."]},{"cell_type":"code","metadata":{"id":"xttwiHh4u0ES"},"source":["def train_model(model, callbacks_list):\n","    '''\n","    Input: \n","        Model and callback list,\n","    Return: \n","        Model with best-checkpoint weights.\n","    '''\n","    ## TYPE YOUR CODE for task 10 here:\n","\n","    return model\n","\n","model = train_model(model, callbacks_list)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QsG02Ao07Mc-"},"source":["**Task 11:** Show the tensorboard in the notebook."]},{"cell_type":"code","metadata":{"id":"jpBk-EKZ2Ut7"},"source":["## TYPE YOUR CODE for task 11 here:"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4z1ed1CY8Rxh"},"source":["**Task 12:** Prediction on test set.\n","\n","* Complete the get_prediction_classes function.\n","* Print out the precision, recall and F1 score."]},{"cell_type":"code","metadata":{"id":"gHTjBLZYvx26"},"source":["def get_prediction_classes(model, X, y):\n","    ## TYPE YOUR CODE for task 13 here:\n","    '''\n","    Input: \n","        Model and prediction dataset.\n","    Return: \n","        Prediction list and groundtrurth list with predicted classes.\n","    '''\n","\n","\n","\n","    return predictions, groundtruths\n","\n","\n","test_predictions, test_groundtruths = get_prediction_classes(model,  X_te, y_te)\n","print(precision_score(test_predictions, test_groundtruths))\n","print(recall_score(test_predictions, test_groundtruths))\n","print(f1_score(test_predictions, test_groundtruths))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JJwQahjp8hZs"},"source":["**Task 13:** Perform the predicted result on test set using confusion matrix. Remember to show the class name in the confusion matrix."]},{"cell_type":"code","metadata":{"id":"5KKAmOGvv2Be"},"source":["def plot_confusion_matrix(predictions, groundtruth, class_names):\n","    ## TYPE YOUR CODE for task 13 here:\n","\n","\n","\n","\n","    plot.show()\n","class_names = ['valid', 'invalid']\n","plot_confusion_matrix(test_predictions, test_groundtruths, class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fGmUAFDi87Z6"},"source":["**Task 14**: Model finetuning - fine tune the model using some of these approachs:\n","* Increase max epochs, change batch size.\n","* Replace LSTM by GRU units and check if it changes anything.\n","* Add another layer of LSTM/GRU, see if things improve.\n","* Play around with Dense layers (add/# units/etc).\n","* Find preprocessing rules you could add to improve the quality of the data.\n","* Find another GloVe dictionary.\n","Requirement: The F1 score should increase by 2-3%."]},{"cell_type":"code","metadata":{"id":"ELLyczmROE8J"},"source":["## TYPE YOUR CODE for task 14 here:"],"execution_count":null,"outputs":[]}]}